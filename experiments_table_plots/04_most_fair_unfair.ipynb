{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h:\\Codes\\fairreceval\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.evaluator.evaluator import Evaluator\n",
    "    \n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def load_dataset(dataset, list_k):\n",
    "\n",
    "    with open(f\"train_val_test/{dataset}_train.pickle\",\"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    train = pd.DataFrame(data)\n",
    "\n",
    "    with open(f\"train_val_test/{dataset}_valid.pickle\",\"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    val = pd.DataFrame(data)\n",
    "\n",
    "    with open(f\"train_val_test/{dataset}_test.pickle\",\"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    test = pd.DataFrame(data)\n",
    "\n",
    "    config = Config(\n",
    "                model=\"Pop\", \n",
    "                dataset=dataset, \n",
    "                config_file_list=[\"RecBole/recbole/properties/overall.yaml\"],\n",
    "                config_dict={\"topk\":list_k,\"metrics\":\"FairWORel\"}\n",
    "                )\n",
    "    evaluator = Evaluator(config)\n",
    "\n",
    "    item_id = config.final_config_dict[\"ITEM_ID_FIELD\"]\n",
    "\n",
    "    train = train.groupby(\"user_id\")\\\n",
    "        .agg(lambda x: [x for x in x])\\\n",
    "        [item_id]\n",
    "\n",
    "    val = val.groupby(\"user_id\")\\\n",
    "        .agg(lambda x: [x for x in x])\\\n",
    "        [item_id]\n",
    "\n",
    "    test = test.groupby(\"user_id\")\\\n",
    "        .agg(lambda x: [x for x in x])\\\n",
    "        [item_id]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"train\"] = train.apply(set)\n",
    "    df[\"valid\"] = val.apply(set)\n",
    "    df[\"pure_test\"] = test.apply(set)\n",
    "\n",
    "    df_test = df[~df.pure_test.isna()]\n",
    "\n",
    "    df = df.applymap(lambda x: set() if type(x) == float else x)\n",
    "    df_test = df_test.applymap(lambda x: set() if type(x) == float else x)\n",
    "    return df, df_test, test, evaluator\n",
    "\n",
    "\n",
    "def get_least_pop_filtered_item(df, user_id, k):\n",
    "    avail_item = df.loc[user_id, \"recommendable_items\"]\n",
    "\n",
    "    if len(avail_item) == 0:\n",
    "        user_with_no_item_to_recommend.append(user_id)\n",
    "    else:\n",
    "        freq_count = curr_rec_count.copy()\n",
    "        #filter those that are not available\n",
    "        for key in freq_count.keys():\n",
    "            if key not in avail_item:\n",
    "                freq_count[key] = 0\n",
    "        freq_count = +freq_count #remove zero and negative counts\n",
    "        for item in avail_item:\n",
    "            if item not in freq_count.keys():\n",
    "                freq_count[item] = 0\n",
    "\n",
    "        #add avail_item as keys with 0 values if not in the freq_count yet\n",
    "        n_least_common = freq_count.most_common()[:-k-1:-1]\n",
    "\n",
    "    return n_least_common\n",
    "\n",
    "def check():\n",
    "    #check that there is no intersection between the items in train_val of a user with their recommendation list\n",
    "    check = pd.DataFrame()\n",
    "    check[\"train\"] = df_test.reset_index(drop=True).train\n",
    "    check[\"valid\"] = df_test.reset_index(drop=True).valid\n",
    "    check[\"curr_test\"] = temp_df.non_repeatable_fair.apply(set)\n",
    "    check = check.dropna()\n",
    "    assert check.apply(lambda x: x.train.intersection(x.curr_test), axis=1).apply(len).value_counts().shape[0] == 1\n",
    "    assert check.apply(lambda x: x.valid.intersection(x.curr_test), axis=1).apply(len).value_counts().shape[0] == 1\n",
    "\n",
    "    #ensure the k recommended items are unique\n",
    "    assert all(check.curr_test.apply(len) == k) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Amazon_Luxury_Beauty\n",
      "Number of items in test that have not been recommended in train or val:  1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "Doing lastfm\n",
      "Number of items in test that have not been recommended in train or val:  0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "Doing ml-1m\n",
      "Number of items in test that have not been recommended in train or val:  0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "Doing book-crossing\n",
      "Number of items in test that have not been recommended in train or val:  0\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "Doing Amazon_Industrial_and_Scientific\n",
      "Number of items in test that have not been recommended in train or val:  1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "Doing Amazon_Digital_Music\n",
      "Number of items in test that have not been recommended in train or val:  1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "list_k = [\n",
    "    1,2,3,5,10,15,20\n",
    "    ]\n",
    "max_k = max(list_k)\n",
    "all_results = pd.DataFrame()\n",
    "for dataset in [\n",
    "            \"Amazon_Luxury_Beauty\",\n",
    "            \"lastfm\", \n",
    "            \"ml-1m\",\n",
    "            \"book-crossing\",\n",
    "            \"Amazon_Industrial_and_Scientific\",\n",
    "            \"Amazon_Digital_Music\",\n",
    "            ]:\n",
    "\n",
    "    print(f\"Doing {dataset}\")\n",
    "\n",
    "    df, df_test, test, evaluator = load_dataset(dataset, list_k)\n",
    "    items_in_train = set(df.train.apply(list).sum())\n",
    "    items_in_val  = set(df.valid.apply(list).sum())\n",
    "    items_in_test  = set(df_test.pure_test.apply(list).sum())\n",
    "\n",
    "    # Repeatable recommendation Most unfair\n",
    "    all_items = items_in_train | items_in_val | items_in_test #add sets\n",
    "\n",
    "    list_all_items = list(all_items)\n",
    "\n",
    "    df_test[\"unfair_repeatable_rec\"] = pd.Series(dtype=object)\n",
    "    df_test[\"unfair_repeatable_rec\"] = df_test[\"unfair_repeatable_rec\"].apply(lambda x: list_all_items[:max_k])\n",
    "    list_file = os.listdir(\"struct/\")\n",
    "    file_for_dataset = [x for x in list_file if dataset in x]\n",
    "    assert len(file_for_dataset) == 1\n",
    "\n",
    "    with open(\"struct/\"+file_for_dataset[0],\"rb\") as f:\n",
    "        struct = pickle.load(f)\n",
    "\n",
    "    rec = torch.Tensor(df_test.unfair_repeatable_rec.apply(lambda x: x).to_list())\n",
    "    struct.set(\"rec.items\",rec)\n",
    "\n",
    "    most_unfair_result_repeatable = evaluator.evaluate(struct)\n",
    "\n",
    "    # NON-REPEATABLE Most unfair\n",
    "    items_in_train_val = df.train.apply(list).sum() + df.valid.apply(list).sum()\n",
    "    test_item_not_in_train_val = set(df.pure_test.apply(list).sum()) - set(items_in_train_val)\n",
    "    print(\"Number of items in test that have not been recommended in train or val: \", len(test_item_not_in_train_val))\n",
    "\n",
    "    freq_count = Counter(items_in_train_val)\n",
    "    for item in test_item_not_in_train_val:\n",
    "        freq_count[item] = 0\n",
    "    \n",
    "    #get $k$ least popular items in train+val\n",
    "    least_recommended_freq_count = freq_count.most_common()[::-1]\n",
    "\n",
    "    least_recommended_items = [item[0] for item in least_recommended_freq_count]\n",
    "\n",
    "    df_test[\"recommendable_items\"] = df_test.apply(lambda x: [item for item in least_recommended_items if item not in x.train and item not in x.valid], axis=1)\n",
    "    #most_unfair\n",
    "\n",
    "    df_test[\"unfair_nonrepeatable_rec\"] = pd.Series(dtype=object)\n",
    "    df_test[\"unfair_nonrepeatable_rec\"] = df_test[\"recommendable_items\"].apply(lambda x: x[:max_k])\n",
    "\n",
    "    rec = torch.Tensor(df_test.unfair_nonrepeatable_rec.to_list())\n",
    "    struct.set(\"rec.items\",rec)\n",
    "\n",
    "    most_unfair_result_nonrepeatable = evaluator.evaluate(struct)\n",
    "\n",
    "    ## Most fair\n",
    "    most_fair_result_repeatable = OrderedDict()\n",
    "    most_fair_result_nonrepeatable = OrderedDict()\n",
    "    m = len(df_test)\n",
    "    for k in list_k:\n",
    "        print(k)\n",
    "        \n",
    "        slots = k*m\n",
    "        multiples = slots//len(list_all_items) + 1\n",
    "        config = Config(\n",
    "                model=\"Pop\", \n",
    "                dataset=dataset, \n",
    "                config_file_list=[\"RecBole/recbole/properties/overall.yaml\"],\n",
    "                config_dict={\"topk\":[k],\"metrics\":\"FairWORel\"}\n",
    "                )\n",
    "        evaluator = Evaluator(config)\n",
    "\n",
    "        #REPEATABLE\n",
    "        rec_list = np.array(list_all_items*multiples)[:slots].reshape(m, k)\n",
    "        rec = torch.Tensor(rec_list)\n",
    "        struct.set(\"rec.items\",torch.clone(rec))\n",
    "\n",
    "        result = evaluator.evaluate(struct)\n",
    "        most_fair_result_repeatable.update(result)\n",
    "\n",
    "        #NONREPEATABLE\n",
    "        user_with_no_item_to_recommend = []\n",
    "        temp = pd.Series(rec_list.tolist())\n",
    "        temp_df = pd.DataFrame()\n",
    "        temp_df[\"repeatable_fair\"] = temp\n",
    "        temp_df[\"recommendable_items\"] = df_test[\"recommendable_items\"].reset_index(drop=True)\n",
    "\n",
    "        temp_df[\"non_repeatable_fair\"] = pd.Series([[]]*len(temp_df))\n",
    "        \n",
    "        for i, row in temp_df.iterrows():\n",
    "            if i == 0:\n",
    "                init_rec = temp_df.at[i,\"recommendable_items\"][:k]\n",
    "                temp_df.at[i,\"non_repeatable_fair\"] = init_rec\n",
    "                curr_rec_count = Counter(init_rec)\n",
    "            else:\n",
    "                items_to_add_and_count = get_least_pop_filtered_item(temp_df, i, k)\n",
    "                items_to_add = [x[0] for x in items_to_add_and_count]\n",
    "                temp_df.at[i, \"non_repeatable_fair\"] = items_to_add\n",
    "\n",
    "                #update curr_rec_count\n",
    "                for_update = Counter(items_to_add)\n",
    "                curr_rec_count.update(for_update)  \n",
    "\n",
    "            \n",
    "        check()   \n",
    "\n",
    "\n",
    "        rec_list = temp_df.non_repeatable_fair.to_list()\n",
    "        rec = torch.Tensor(rec_list)\n",
    "        struct.set(\"rec.items\",torch.clone(rec))\n",
    "\n",
    "        result = evaluator.evaluate(struct)\n",
    "        most_fair_result_nonrepeatable.update(result)\n",
    "        if len(user_with_no_item_to_recommend) > 0:\n",
    "            print(user_with_no_item_to_recommend)\n",
    "\n",
    "    result_df = pd.DataFrame(columns=[\"most_unfair_repeatable\",\"most_fair_repeatable\"])\n",
    "    result_df.most_fair_repeatable = most_fair_result_repeatable\n",
    "    result_df.most_unfair_repeatable = most_unfair_result_repeatable\n",
    "    result_df[\"most_fair_nonrepeatable\"] = most_fair_result_nonrepeatable\n",
    "    result_df[\"most_unfair_nonrepeatable\"] = most_unfair_result_nonrepeatable\n",
    "\n",
    "    \n",
    "    #save result_df for each dataset\n",
    "    result_df = result_df.reset_index()\n",
    "    if dataset == \"Amazon_Luxury_Beauty\":\n",
    "        dataset = \"amazon-lb\"\n",
    "    elif dataset == \"Amazon_Industrial_and_Scientific\":\n",
    "        dataset = \"amazon-is\"\n",
    "    elif dataset == \"book-crossing\":\n",
    "        dataset = \"book-x\"\n",
    "    elif dataset == \"Amazon_Digital_Music\":\n",
    "        dataset = \"amazon-dm\"\n",
    "    result_df.index = [dataset]*len(result_df)\n",
    "    result_df.rename(columns={\"index\":\"measure\"},inplace=True)\n",
    "    result_df.index.set_names(\"dataset\", inplace=True)\n",
    "    all_results = all_results.append(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [sublist[1] for sublist in all_results.measure.str.split(\"@\")]\n",
    "all_results[\"k\"] = k\n",
    "all_results.measure = all_results.measure.str.replace(\"@\\d*\",\"\",regex=True)\n",
    "ori_our = [sublist[1] for sublist in all_results.measure.str.split(\"_\")]\n",
    "all_results[\"version\"] = ori_our\n",
    "all_results.measure = all_results.measure.str.replace(\"_.*\",\"\",regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.to_excel(\"most_fair_unfair_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_order = all_results[\"measure\"].unique()\n",
    "\n",
    "grouped = all_results.set_index([all_results.index,\"k\",\"version\",\"measure\"])\n",
    "grouped.index.set_names(['dataset','k', 'version'], level=[0,1,2], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.to_excel(\"grouped_most_fair_unfair_all.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:,.5f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>most_unfair_repeatable</th>\n",
       "      <th>most_fair_repeatable</th>\n",
       "      <th>most_fair_nonrepeatable</th>\n",
       "      <th>most_unfair_nonrepeatable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>k</th>\n",
       "      <th>version</th>\n",
       "      <th>measure</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">amazon-lb</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>ori</th>\n",
       "      <th>Jain</th>\n",
       "      <td>0.00126</td>\n",
       "      <td>0.98355</td>\n",
       "      <td>0.98355</td>\n",
       "      <td>0.00126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>our</th>\n",
       "      <th>Jain</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ori</th>\n",
       "      <th>QF</th>\n",
       "      <td>0.00126</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>our</th>\n",
       "      <th>QF</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ori</th>\n",
       "      <th>Ent</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99889</td>\n",
       "      <td>0.99889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">amazon-dm</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">20</th>\n",
       "      <th>our</th>\n",
       "      <th>Gini</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ori</th>\n",
       "      <th>Gini-w</th>\n",
       "      <td>0.99836</td>\n",
       "      <td>0.05001</td>\n",
       "      <td>0.04973</td>\n",
       "      <td>0.99836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSat</th>\n",
       "      <td>0.00211</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>our</th>\n",
       "      <th>FSat</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ori</th>\n",
       "      <th>VoCD</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01096</td>\n",
       "      <td>0.01096</td>\n",
       "      <td>0.09507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              most_unfair_repeatable  most_fair_repeatable  \\\n",
       "dataset   k  version measure                                                 \n",
       "amazon-lb 1  ori     Jain                    0.00126               0.98355   \n",
       "             our     Jain                    0.00000               1.00000   \n",
       "             ori     QF                      0.00126               1.00000   \n",
       "             our     QF                      0.00000               1.00000   \n",
       "             ori     Ent                         NaN               0.99889   \n",
       "...                                              ...                   ...   \n",
       "amazon-dm 20 our     Gini                    1.00000               0.00000   \n",
       "             ori     Gini-w                  0.99836               0.05001   \n",
       "                     FSat                    0.00211               1.00000   \n",
       "             our     FSat                    0.00000               1.00000   \n",
       "             ori     VoCD                    0.00000               0.01096   \n",
       "\n",
       "                              most_fair_nonrepeatable  \\\n",
       "dataset   k  version measure                            \n",
       "amazon-lb 1  ori     Jain                     0.98355   \n",
       "             our     Jain                     1.00000   \n",
       "             ori     QF                       1.00000   \n",
       "             our     QF                       1.00000   \n",
       "             ori     Ent                      0.99889   \n",
       "...                                               ...   \n",
       "amazon-dm 20 our     Gini                     0.00000   \n",
       "             ori     Gini-w                   0.04973   \n",
       "                     FSat                     1.00000   \n",
       "             our     FSat                     1.00000   \n",
       "             ori     VoCD                     0.01096   \n",
       "\n",
       "                              most_unfair_nonrepeatable  \n",
       "dataset   k  version measure                             \n",
       "amazon-lb 1  ori     Jain                       0.00126  \n",
       "             our     Jain                       0.00000  \n",
       "             ori     QF                         0.00126  \n",
       "             our     QF                         0.00000  \n",
       "             ori     Ent                            NaN  \n",
       "...                                                 ...  \n",
       "amazon-dm 20 our     Gini                       1.00000  \n",
       "             ori     Gini-w                     0.99836  \n",
       "                     FSat                       0.00222  \n",
       "             our     FSat                       0.00011  \n",
       "             ori     VoCD                       0.09507  \n",
       "\n",
       "[504 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairreceval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe0d571e343c00b66bb6a6b9f25fbc50947e8e28daf577955b94753bab898243"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
